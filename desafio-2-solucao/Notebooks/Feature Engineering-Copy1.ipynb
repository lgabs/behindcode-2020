{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# MARATONA BEHIND THE CODE 2020\n",
    "\n",
    "## DESAFIO 2: PARTE 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na parte 1 deste desafio, você realizou o pré-processamento e o treinamento de um modelo a partir de um conjunto de dados base fornecido. Nesta segunda etapa você irá integrar todas as transformações e eventos de treinamento criados anteriormente em uma Pipeline completa para *deploy* no **Watson Machine Learning**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparação do Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primeiro realizaremos a instalação do scikit-learn e a importação das mesmas bibliotecas utilizadas anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T10:43:05.584245Z",
     "start_time": "2020-08-20T10:43:00.832260Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /home/luan/anaconda3/lib/python3.7/site-packages (1.1.1)\n",
      "Requirement already satisfied: numpy in /home/luan/.local/lib/python3.7/site-packages (from xgboost) (1.16.3)\n",
      "Requirement already satisfied: scipy in /home/luan/anaconda3/lib/python3.7/site-packages (from xgboost) (1.3.2)\n",
      "Requirement already satisfied: scikit-optimize in /home/luan/anaconda3/lib/python3.7/site-packages (0.7.4)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /home/luan/anaconda3/lib/python3.7/site-packages (from scikit-optimize) (0.20.4)\n",
      "Requirement already satisfied: pyaml>=16.9 in /home/luan/anaconda3/lib/python3.7/site-packages (from scikit-optimize) (20.4.0)\n",
      "Requirement already satisfied: scipy>=0.18.0 in /home/luan/anaconda3/lib/python3.7/site-packages (from scikit-optimize) (1.3.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/luan/.local/lib/python3.7/site-packages (from scikit-optimize) (0.13.2)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /home/luan/.local/lib/python3.7/site-packages (from scikit-optimize) (1.16.3)\n",
      "Requirement already satisfied: PyYAML in /home/luan/anaconda3/lib/python3.7/site-packages (from pyaml>=16.9->scikit-optimize) (5.2)\n"
     ]
    }
   ],
   "source": [
    "# # Primeiro, realizamos a instalação do scikit-learn versão 0.20.0 no Kernel deste notebook:\n",
    "# !pip install numpy==1.16.4 --upgrade\n",
    "# !pip install pandas==0.24.2 --upgrade\n",
    "# !pip install scikit-learn==0.20.3 --upgrade\n",
    "# !pip install lightgbm\n",
    "!pip install xgboost\n",
    "!pip install scikit-optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T10:43:05.593294Z",
     "start_time": "2020-08-20T10:43:05.586341Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgbm\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import KFold, cross_validate\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_val_score,\n",
    "    GridSearchCV,\n",
    "    learning_curve,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T10:43:05.651214Z",
     "start_time": "2020-08-20T10:43:05.595623Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MATRICULA</th>\n",
       "      <th>NOME</th>\n",
       "      <th>REPROVACOES_DE</th>\n",
       "      <th>REPROVACOES_EM</th>\n",
       "      <th>REPROVACOES_MF</th>\n",
       "      <th>REPROVACOES_GO</th>\n",
       "      <th>NOTA_DE</th>\n",
       "      <th>NOTA_EM</th>\n",
       "      <th>NOTA_MF</th>\n",
       "      <th>NOTA_GO</th>\n",
       "      <th>INGLES</th>\n",
       "      <th>H_AULA_PRES</th>\n",
       "      <th>TAREFAS_ONLINE</th>\n",
       "      <th>FALTAS</th>\n",
       "      <th>PERFIL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>502375</td>\n",
       "      <td>Márcia Illiglener</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>5.8</td>\n",
       "      <td>4.6</td>\n",
       "      <td>5.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>EXATAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>397093</td>\n",
       "      <td>Jason Jytereoman Izoimum</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.2</td>\n",
       "      <td>5.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>EXATAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>915288</td>\n",
       "      <td>Bartolomeu Inácio da Gama</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>6.7</td>\n",
       "      <td>7.1</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>HUMANAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192652</td>\n",
       "      <td>Fernanda Guedes</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>DIFICULDADE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>949491</td>\n",
       "      <td>Alessandre Borba Gomes</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>DIFICULDADE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MATRICULA                       NOME  REPROVACOES_DE  REPROVACOES_EM  \\\n",
       "0     502375          Márcia Illiglener               0               0   \n",
       "1     397093   Jason Jytereoman Izoimum               0               0   \n",
       "2     915288  Bartolomeu Inácio da Gama               0               0   \n",
       "3     192652            Fernanda Guedes               1               3   \n",
       "4     949491     Alessandre Borba Gomes               1               3   \n",
       "\n",
       "   REPROVACOES_MF  REPROVACOES_GO  NOTA_DE  NOTA_EM  NOTA_MF  NOTA_GO  INGLES  \\\n",
       "0               0               0      6.2      5.8      4.6      5.9     0.0   \n",
       "1               0               0      6.0      6.2      5.2      4.5     1.0   \n",
       "2               0               0      7.3      6.7      7.1      7.2     0.0   \n",
       "3               1               1      0.0      0.0      0.0      0.0     1.0   \n",
       "4               1               1      0.0      0.0      0.0      0.0     1.0   \n",
       "\n",
       "   H_AULA_PRES  TAREFAS_ONLINE  FALTAS       PERFIL  \n",
       "0            2               4       3       EXATAS  \n",
       "1            2               4       3       EXATAS  \n",
       "2            5               0       3      HUMANAS  \n",
       "3            4               4       4  DIFICULDADE  \n",
       "4            5               2       5  DIFICULDADE  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# << INSIRA O DATASET COMO UM DATAFRAME PANDAS NESTA CÉLULA >>\n",
    "import types\n",
    "import pandas as pd\n",
    "\n",
    "df_data_1 = pd.read_csv(\"../Data/dataset_desafio_2.csv\")\n",
    "df_data_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construção da Pipeline completa para encapsulamento no WML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T10:43:05.657820Z",
     "start_time": "2020-08-20T10:43:05.653241Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "\n",
    "# All sklearn Transforms must have the `transform` and `fit` methods\n",
    "class DropColumns(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Primeiro realizamos a cópia do dataframe 'X' de entrada\n",
    "        data = X.copy()\n",
    "        # Retornamos um novo dataframe sem as colunas indesejadas\n",
    "        return data.drop(labels=self.columns, axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declarando a Pipeline\n",
    "\n",
    "Após a importação das transformações personalizadas como um pacote Python, podemos partir para a declaração da nossa Pipeline.\n",
    "\n",
    "O processo é bem semelhante ao realizado na primeira etapa, porém com algumas diferenças importantes, então preste bem atenção!\n",
    "\n",
    "A Pipeline exemplo possui três estágios: \n",
    "\n",
    "    - remover a coluna \"NOME\"\n",
    "    - imputar \"zeros\" em todos os valores faltantes\n",
    "    - inserir os dados pré-processados como entrada em um modelo treinado\n",
    "    \n",
    "Relembrando, a entrada desta Pipeline será o conjunto cru de dados fornecido exceto a coluna \"LABELS\" (variável-alvo a ser determinada pelo modelo).\n",
    "\n",
    "Teremos então 17 valores de entrada **na PIPELINE** (no modelo serão 16 entradas, pois a coluna NAME será removida no primeiro estágio após a transformação DropColumn).\n",
    "\n",
    "    MATRICULA       - número de quatro algarismos único para cada estudante\n",
    "    NOME            - nome completo do estudante\n",
    "    FALTAS_DE       - número de faltas na disciplina de ``Direito Empresarial``\n",
    "    FALTAS_EM       - número de faltas na disciplina de ``Empreendedorismo``\n",
    "    FALTAS_MF       - número de faltas na disciplina de ``Matemática Financeira``\n",
    "    MEDIA_DE        - média simples das notas do aluno na disciplina de ``Direito Empresarial`` (0-10)\n",
    "    MEDIA_EM        - média simples das notas do aluno na disciplina de ``Empreendedorismo`` (0-10)\n",
    "    MEDIA_MF        - média simples das notas do aluno na disciplina de ``Matemática Financeira`` (0-10)\n",
    "    HRS_ESTUDO_DE   - horas de estudo particular na disciplina de ``Direito Empresarial``\n",
    "    HRS_ESTUDO_EM   - horas de estudo particular na disciplina de ``Empreendedorismo``\n",
    "    HRS_ESTUDO_MF   - horas de estudo particular na disciplina de ``Matemática Financeira``\n",
    "    REPROVACOES_DE  - número de reprovações na disciplina de ``Direito Empresarial``\n",
    "    REPROVACOES_EM  - número de reprovações na disciplina de ``Empreendedorismo``\n",
    "    REPROVACOES_MF  - número de reprovações na disciplina de ``Matemática Financeira``\n",
    "    LIVROS_TEXTO    - quantidade de livros e textos acessados pelo aluno no sistema da universidade\n",
    "    AULAS_AO_VIVO   - horas de aulas ao vivo presenciadas pelo aluno (total em todas as disciplinas)\n",
    "    EXERCICIOS      - número de exercícios realizados pelo estudante (total em todas as disciplinas) no sistema da universidade\n",
    "\n",
    "A saída da Pipeline será um valor estimado para a coluna \"LABELS\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T10:43:05.672514Z",
     "start_time": "2020-08-20T10:43:05.659935Z"
    }
   },
   "outputs": [],
   "source": [
    "# Criação de uma Transform personalizada ``DropColumns``\n",
    "\n",
    "rm_columns = DropColumns(\n",
    "    columns=[\"NOME\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T10:46:33.283791Z",
     "start_time": "2020-08-20T10:46:33.280228Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T10:44:49.198838Z",
     "start_time": "2020-08-20T10:44:49.186405Z"
    }
   },
   "outputs": [],
   "source": [
    "# Definição das colunas que serão features (nota-se que a coluna NOME não está presente)\n",
    "features = [\n",
    "    \"MATRICULA\", \"NOME\", 'REPROVACOES_DE', 'REPROVACOES_EM', \"REPROVACOES_MF\", \"REPROVACOES_GO\",\n",
    "    \"NOTA_DE\", \"NOTA_EM\", \"NOTA_MF\", \"NOTA_GO\",\n",
    "    \"INGLES\", \"H_AULA_PRES\", \"TAREFAS_ONLINE\", \"FALTAS\", \n",
    "]\n",
    "\n",
    "# Definição da variável-alvo\n",
    "target = [\"PERFIL\"]\n",
    "\n",
    "# Preparação dos argumentos para os métodos da biblioteca ``scikit-learn``\n",
    "X = df_data_1[features]\n",
    "y = df_data_1[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ATENÇÃO!!**\n",
    "\n",
    "A célula acima, embora muito parecida com a definição de features na primeira etapa deste desafio, possui uma grande diferença!\n",
    "\n",
    "Nela está presente a coluna \"NOME\" como uma feature! Isso ocorre pois neste caso essas são as entradas da *PIPELINE*, e não do modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T10:44:52.778930Z",
     "start_time": "2020-08-20T10:44:52.755470Z"
    }
   },
   "outputs": [],
   "source": [
    "# Separação dos dados em um conjunto de treino e um conjunto de teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na célula abaixo é realizada a declaração de um objeto **Pipeline** do scikit-learn, onde é declarado o parâmetro *steps*, que nada mais é do que uma lista com as etapas da nossa pipeline:\n",
    "\n",
    "    'remove_cols'     - transformação personalizada DropColumns\n",
    "    'imputer'         - transformação embutida do scikit-learn para imputação de valores faltantes\n",
    "    'dtc'             - um classificador via árvore de decisão\n",
    "    \n",
    "Note que passamos como passos as transformadas instanciadas anteriormente, sob nome `rm_columns` e `si`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T10:44:53.867895Z",
     "start_time": "2020-08-20T10:44:53.858622Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 14 columns):\n",
      "MATRICULA         20000 non-null int64\n",
      "NOME              20000 non-null object\n",
      "REPROVACOES_DE    20000 non-null int64\n",
      "REPROVACOES_EM    20000 non-null int64\n",
      "REPROVACOES_MF    20000 non-null int64\n",
      "REPROVACOES_GO    20000 non-null int64\n",
      "NOTA_DE           20000 non-null float64\n",
      "NOTA_EM           20000 non-null float64\n",
      "NOTA_MF           20000 non-null float64\n",
      "NOTA_GO           16284 non-null float64\n",
      "INGLES            16372 non-null float64\n",
      "H_AULA_PRES       20000 non-null int64\n",
      "TAREFAS_ONLINE    20000 non-null int64\n",
      "FALTAS            20000 non-null int64\n",
      "dtypes: float64(5), int64(8), object(1)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T10:45:32.166441Z",
     "start_time": "2020-08-20T10:45:32.163593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size:  14000\n",
      "train size:  6000\n"
     ]
    }
   ],
   "source": [
    "print(\"train size: \", len(X_train))\n",
    "print(\"train size: \",len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LGBM sem tunning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T10:49:56.713148Z",
     "start_time": "2020-08-20T10:49:56.706141Z"
    }
   },
   "outputs": [],
   "source": [
    "# Criação de um objeto ``SimpleImputer``\n",
    "\n",
    "si = SimpleImputer(\n",
    "    missing_values=np.nan,  # os valores faltantes são do tipo ``np.nan`` (padrão Pandas)\n",
    "    strategy='mean',  # a estratégia escolhida é a alteração do valor faltante por uma constante\n",
    "#     fill_value=0,  # a constante que será usada para preenchimento dos valores faltantes é um int64=0.\n",
    "#     strategy = \"most_frequent\",\n",
    "    verbose=0,\n",
    "    copy=True\n",
    ")\n",
    "\n",
    "# Criação da nossa pipeline para armazenamento no Watson Machine Learning:\n",
    "params = {\n",
    "        \"num_leaves\":2,\n",
    "        \"learning_rate\": 0.5,\n",
    "        \"min_child_samples\": 1,\n",
    "        \"subsample\": 0.05,\n",
    "        \"colsample_bytree\": 0.1,\n",
    "        \"random_state\":42,\n",
    "    \n",
    "}\n",
    "\n",
    "clf =  lgbm.LGBMClassifier()\n",
    "# clf_xgb = XGBClassifier(verbose=1)\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('remove_cols', rm_columns),\n",
    "        ('imputer', si),\n",
    "        ('clf', clf),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T10:49:57.647801Z",
     "start_time": "2020-08-20T10:49:56.913238Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('remove_cols', DropColumns(columns=['NOME'])), ('imputer', SimpleImputer(copy=True, fill_value=None, missing_values=nan, strategy='mean',\n",
       "       verbose=0)), ('clf', LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "        importance_type='split', learning_rate=0...0, reg_lambda=0.0, silent=True,\n",
       "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0))])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inicialização da Pipeline (pré-processamento e realização do treinamento do modelo)\n",
    "pipeline.fit(X_train, y_train.values.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T10:49:57.758319Z",
     "start_time": "2020-08-20T10:49:57.650648Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acurácia: 80.93%\n"
     ]
    }
   ],
   "source": [
    "# Realização de teste cego no modelo criado\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Acurácia alcançada pela árvore de decisão\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"Acurácia: {}%\".format(100*round(accuracy_score(y_test, y_pred), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T10:46:08.238663Z",
     "start_time": "2020-08-20T10:46:08.163007Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      " DIFICULDADE       0.87      0.75      0.81      2111\n",
      "      EXATAS       0.80      0.90      0.85      2455\n",
      "   EXCELENTE       0.62      0.66      0.64       217\n",
      "     HUMANAS       0.77      0.90      0.83       937\n",
      "   MUITO_BOM       0.31      0.12      0.17       280\n",
      "\n",
      "   micro avg       0.80      0.80      0.80      6000\n",
      "   macro avg       0.68      0.67      0.66      6000\n",
      "weighted avg       0.79      0.80      0.79      6000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tunando LGBM com Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T23:30:54.678022Z",
     "start_time": "2020-08-19T23:30:54.670962Z"
    }
   },
   "outputs": [],
   "source": [
    "# ratio_neg = sum(X) / sum(positive instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-20T10:51:11.890627Z",
     "start_time": "2020-08-20T10:50:51.509360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration No: 1 started. Evaluating function at random point.\n",
      "Iteration No: 1 ended. Evaluation done at random point.\n",
      "Time taken: 2.7322\n",
      "Function value obtained: -0.6214\n",
      "Current minimum: -0.6214\n",
      "Iteration No: 2 started. Evaluating function at random point.\n",
      "Iteration No: 2 ended. Evaluation done at random point.\n",
      "Time taken: 1.7604\n",
      "Function value obtained: -0.8134\n",
      "Current minimum: -0.8134\n",
      "Iteration No: 3 started. Evaluating function at random point.\n",
      "Iteration No: 3 ended. Evaluation done at random point.\n",
      "Time taken: 1.0900\n",
      "Function value obtained: -0.8096\n",
      "Current minimum: -0.8134\n",
      "Iteration No: 4 started. Evaluating function at random point.\n",
      "Iteration No: 4 ended. Evaluation done at random point.\n",
      "Time taken: 2.8736\n",
      "Function value obtained: -0.8076\n",
      "Current minimum: -0.8134\n",
      "Iteration No: 5 started. Evaluating function at random point.\n",
      "Iteration No: 5 ended. Evaluation done at random point.\n",
      "Time taken: 1.4493\n",
      "Function value obtained: -0.5897\n",
      "Current minimum: -0.8134\n",
      "Iteration No: 6 started. Searching for the next optimal point.\n",
      "Iteration No: 6 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.8602\n",
      "Function value obtained: -0.8144\n",
      "Current minimum: -0.8144\n",
      "Iteration No: 7 started. Searching for the next optimal point.\n",
      "Iteration No: 7 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.9210\n",
      "Function value obtained: -0.8149\n",
      "Current minimum: -0.8149\n",
      "Iteration No: 8 started. Searching for the next optimal point.\n",
      "Iteration No: 8 ended. Search finished for the next optimal point.\n",
      "Time taken: 0.9551\n",
      "Function value obtained: -0.7964\n",
      "Current minimum: -0.8149\n",
      "Iteration No: 9 started. Searching for the next optimal point.\n",
      "Iteration No: 9 ended. Search finished for the next optimal point.\n",
      "Time taken: 3.2106\n",
      "Function value obtained: -0.7950\n",
      "Current minimum: -0.8149\n",
      "Iteration No: 10 started. Searching for the next optimal point.\n",
      "Iteration No: 10 ended. Search finished for the next optimal point.\n",
      "Time taken: 4.4336\n",
      "Function value obtained: -0.7921\n",
      "Current minimum: -0.8149\n"
     ]
    }
   ],
   "source": [
    "from skopt import gp_minimize\n",
    "from skopt.plots import plot_convergence\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "# The list of hyper-parameters we want to optimize\n",
    "space = [\n",
    "    Integer(2, 256, name=\"num_leaves\"),\n",
    "    Real(10 ** -3, 0.5, \"log-uniform\", name=\"learning_rate\"),\n",
    "    Integer(1, 256, name=\"min_child_samples\"),\n",
    "    Real(0.05, 1.00, name=\"subsample\"),\n",
    "    Real(0.1, 1.00, name=\"colsample_bytree\"),\n",
    "]\n",
    "\n",
    "# space = [\n",
    "#     Integer(5,50, name=\"max_depth\"),\n",
    "#     Integer(1,15, name=\"min_child_weight\"),\n",
    "#     Real(0.4, 1, name=\"subsample\"),\n",
    "#     Integer(10, 11, name=\"n_estimators\")\n",
    "    \n",
    "# ]\n",
    "\n",
    "params_names = [dim.name for dim in space]\n",
    "\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    clf.set_params(**params)\n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            ('remove_cols', rm_columns),\n",
    "            ('imputer', si),\n",
    "            ('clf', clf),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return -np.mean(cross_val_score(pipeline, X_train, y_train, cv=3, n_jobs=-1,\n",
    "                            scoring=\"accuracy\"))\n",
    "\n",
    "# do bayesian optimization\n",
    "\n",
    "clf = lgbm.LGBMClassifier(random_state=42)\n",
    "# clf = XGBClassifier()\n",
    "\n",
    "result_gp = gp_minimize(\n",
    "    objective, space, random_state=42, verbose=1, n_calls=10, n_random_starts=5\n",
    ")\n",
    "\n",
    "# get best params and make the best classifier\n",
    "best_params = dict(zip(params_names, result_gp.x))\n",
    "\n",
    "# best_clf = XGBClassifier(**best_params)\n",
    "best_clf = lgbm.LGBMClassifier(**best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T23:46:21.843503Z",
     "start_time": "2020-08-19T23:46:21.532794Z"
    }
   },
   "outputs": [],
   "source": [
    "# Acurácia alcançada pela árvore de decisão\n",
    "best_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('remove_cols', rm_columns),\n",
    "        ('imputer', si),\n",
    "        ('clf', best_clf),\n",
    "    ]\n",
    ")\n",
    "best_pipeline.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "print(\"Acurácia: {}%\".format(100*round(accuracy_score(y_test, y_pred), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XgBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T23:47:20.681751Z",
     "start_time": "2020-08-19T23:47:05.224422Z"
    }
   },
   "outputs": [],
   "source": [
    "from skopt import gp_minimize\n",
    "from skopt.plots import plot_convergence\n",
    "from skopt.utils import use_named_args\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "# The list of hyper-parameters we want to optimize\n",
    "space = [\n",
    "    Integer(2, 256, name=\"num_leaves\"),\n",
    "    Real(10 ** -3, 0.5, \"log-uniform\", name=\"learning_rate\"),\n",
    "    Integer(1, 256, name=\"min_child_samples\"),\n",
    "    Real(0.05, 1.00, name=\"subsample\"),\n",
    "    Real(0.1, 1.00, name=\"colsample_bytree\"),\n",
    "]\n",
    "\n",
    "\n",
    "params_names = [dim.name for dim in space]\n",
    "\n",
    "@use_named_args(space)\n",
    "def objective(**params):\n",
    "    clf.set_params(**params)\n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            ('remove_cols', rm_columns),\n",
    "            ('imputer', si),\n",
    "            ('clf', clf),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return -np.mean(cross_val_score(pipeline, X_train, y_train, cv=3, n_jobs=-1,\n",
    "                            scoring=\"accuracy\"))\n",
    "\n",
    "# do bayesian optimization\n",
    "\n",
    "_clf = XGBClassifier()\n",
    "\n",
    "result_gp = gp_minimize(\n",
    "    objective, space, random_state=42, verbose=1, n_calls=10, n_random_starts=5\n",
    ")\n",
    "\n",
    "# get best params and make the best classifier\n",
    "best_params = dict(zip(params_names, result_gp.x))\n",
    "\n",
    "best_clf = XGBClassifier(**best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-19T23:47:24.663532Z",
     "start_time": "2020-08-19T23:47:20.684031Z"
    }
   },
   "outputs": [],
   "source": [
    "# Acurácia alcançada pela árvore de decisão\n",
    "best_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('remove_cols', rm_columns),\n",
    "        ('imputer', si),\n",
    "        ('clf', best_clf),\n",
    "    ]\n",
    ")\n",
    "best_pipeline.fit(X_train, y_train.values.ravel())\n",
    "\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "print(\"Acurácia: {}%\".format(100*round(accuracy_score(y_test, y_pred), 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encapsulando uma Pipeline personalizada no Watson Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Estabelecendo conexão entre o cliente Python do WML e a sua instância do serviço na nuvem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biblioteca Python com implementação de um cliente HTTP para a API do WML\n",
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As próximas células irão realizar o deploy da pipeline declarada neste notebook no WML. Só prossiga se você já está satisfeito com seu modelo e acha que já é a hora de fazer o deploy da sua solução.\n",
    "\n",
    "Cole as credenciais de sua instância do Watson Machine Learning na variável na célula abaixo.\n",
    "\n",
    "É importante que a variável que contém os valores tenha o nome de ``wml_credentials`` para que as próximas células deste notebook executem corretamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wml_credentials = {\n",
    "  \"apikey\": \"\",\n",
    "  \"iam_apikey_description\": \"\",\n",
    "  \"iam_apikey_name\": \"\",\n",
    "  \"iam_role_crn\": \"\",\n",
    "  \"iam_serviceid_crn\": \"\",\n",
    "  \"instance_id\": \"\",\n",
    "  \"url\": \"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando um objeto cliente do Watson Machine Learning a partir das credenciais fornecidas\n",
    "\n",
    "clientWML = WatsonMachineLearningAPIClient(wml_credentials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraindo detalhes da sua instância do Watson Machine Learning\n",
    "\n",
    "instance_details = clientWML.service_instance.get_details()\n",
    "print(json.dumps(instance_details, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ATENÇÃO!!**\n",
    "\n",
    "Fique atento para os limites de consumo de sua instância do Watson Machine Learning!\n",
    "\n",
    "Caso você expire a camada grátis, não será possível avaliar seu modelo (pois é necessária a realização de algumas chamadas de API que consomem predições!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Listando todos os artefatos armazenados no seu WML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para listar todos os artefatos armazenados em seu Watson Machine Learning, você pode usar a seguinte função:\n",
    "\n",
    "    clientWML.repository.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listando todos os artefatos atualmente armazenados na sua instância do WML\n",
    "\n",
    "clientWML.repository.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No plano LITE do Watson Machine Learning só é permitido o deploy de um único modelo por vez. Se for o caso de você já possuir um modelo online na sua instância, você pode apagá-lo utilizando o método clientWML.repository.delete():\n",
    "\n",
    "    artifact_guid = \"359c8951-d2fe-4063-8706-cc06b32d5e0d\"\n",
    "    clientWML.repository.delete(artifact_guid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando uma nova definição de pacote Python personalizado no WML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro passo para realizar seu deploy é armazenar o código das transformações personalizadas criadas por você.\n",
    "\n",
    "Para essa etapa precisamos apenas do arquivo .zip do pacote criado (que já possuimos carregado no Kernel!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definição de metadados do nosso pacote com as Transforms personalizadas\n",
    "pkg_meta = {\n",
    "    clientWML.runtimes.LibraryMetaNames.NAME: \"my_custom_sklearn_transform_1\",\n",
    "    clientWML.runtimes.LibraryMetaNames.DESCRIPTION: \"A custom sklearn transform\",\n",
    "    clientWML.runtimes.LibraryMetaNames.FILEPATH: \"sklearn_transforms.zip\",  # Note que estamos utilizando o .zip criado anteriormente!\n",
    "    clientWML.runtimes.LibraryMetaNames.VERSION: \"1.0\",\n",
    "    clientWML.runtimes.LibraryMetaNames.PLATFORM: { \"name\": \"python\", \"versions\": [\"3.6\"] }\n",
    "}\n",
    "custom_package_details = clientWML.runtimes.store_library( pkg_meta )\n",
    "custom_package_uid = clientWML.runtimes.get_library_uid( custom_package_details )\n",
    "\n",
    "print(\"\\n Lista de artefatos de runtime armazenados no WML:\")\n",
    "clientWML.repository.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando uma nova definição de runtime Python personalizado no WML\n",
    "\n",
    "O segundo passo é armazenar uma definição de runtime Python para utilizar a nossa biblioteca personalizada.\n",
    "\n",
    "Isso pode ser feito da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runtime_meta = {\n",
    "    clientWML.runtimes.ConfigurationMetaNames.NAME: \"my_custom_wml_runtime_1\",\n",
    "    clientWML.runtimes.ConfigurationMetaNames.DESCRIPTION: \"A Python runtime with custom sklearn Transforms\",\n",
    "    clientWML.runtimes.ConfigurationMetaNames.PLATFORM: {\n",
    "        \"name\": \"python\",\n",
    "        \"version\": \"3.6\"\n",
    "    },\n",
    "    clientWML.runtimes.ConfigurationMetaNames.LIBRARIES_UIDS: [ custom_package_uid ]\n",
    "}\n",
    "runtime_details = clientWML.runtimes.store( runtime_meta )\n",
    "custom_runtime_uid = clientWML.runtimes.get_uid( runtime_details )\n",
    "\n",
    "print(\"\\n Detalhes do runtime armazenado:\")\n",
    "print(json.dumps(runtime_details, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listando todos runtimes armazenados no seu WML:\n",
    "clientWML.runtimes.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Criando uma nova definição de Pipeline personalizada no WML\n",
    "\n",
    "Finalmente iremos criar uma definição (metadados) para a nossa Pipeline ser hospedada no WML.\n",
    "\n",
    "Definimos como parâmetros um nome para o artefato e o ID do runtime criado anteriormente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_meta = {\n",
    "    clientWML.repository.ModelMetaNames.NAME: 'desafio-2-mbtc2020-pipeline-1',\n",
    "    clientWML.repository.ModelMetaNames.DESCRIPTION: \"my pipeline for submission\",\n",
    "    clientWML.repository.ModelMetaNames.RUNTIME_UID: custom_runtime_uid\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Em seguida chamamos o método para armazenar a nova definição:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para armazenar uma definição de Pipeline no WML\n",
    "stored_model_details = clientWML.repository.store_model(\n",
    "    model=my_pipeline,  # `my_pipeline` é a variável criada anteriormente e contém nossa Pipeline já treinada :)\n",
    "    meta_props=model_meta,  # Metadados definidos na célula anterior\n",
    "    training_data=None  # Não altere esse parâmetro\n",
    ")\n",
    "\n",
    "print(\"\\n Lista de artefatos armazenados no WML:\")\n",
    "clientWML.repository.list()\n",
    "\n",
    "# Detalhes do modelo hospedado no Watson Machine Learning\n",
    "print(\"\\n Metadados do modelo armazenado:\")\n",
    "print(json.dumps(stored_model_details, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Realizando o deployment do seu modelo para consumo imediato por outras aplicações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O deployment do modelo é finalmente realizado por meio do método ``deployments.create()``\n",
    "\n",
    "model_deployment_details = clientWML.deployments.create(\n",
    "    artifact_uid=stored_model_details[\"metadata\"][\"guid\"],  # Não altere esse parâmetro\n",
    "    name=\"desafio-2-mbtc2020-deployment-1\",\n",
    "    description=\"Solução do desafio 2 - MBTC\",\n",
    "    asynchronous=False,  # Não altere esse parâmetro\n",
    "    deployment_type='online',  # Não altere esse parâmetro\n",
    "    deployment_format='Core ML',  # Não altere esse parâmetro\n",
    "    meta_props=model_meta  # Não altere esse parâmetro\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testando um modelo hospedado no Watson Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recuperando a URL endpoint do modelo hospedado na célula anterior\n",
    "\n",
    "model_endpoint_url = clientWML.deployments.get_scoring_url(model_deployment_details)\n",
    "print(\"A URL de chamada da sua API é: {}\".format(model_endpoint_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detalhes do deployment realizado\n",
    "\n",
    "deployment_details = clientWML.deployments.get_details(\n",
    "    deployment_uid=model_deployment_details[\"metadata\"][\"guid\"]  # esse é o ID do seu deployment!\n",
    ")\n",
    "\n",
    "print(\"Metadados do deployment realizado: \\n\")\n",
    "print(json.dumps(deployment_details, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "scoring_payload = {\n",
    "    'fields': [\n",
    "        \"MATRICULA\", \"NOME\", 'REPROVACOES_DE', 'REPROVACOES_EM', \"REPROVACOES_MF\", \"REPROVACOES_GO\",\n",
    "        \"NOTA_DE\", \"NOTA_EM\", \"NOTA_MF\", \"NOTA_GO\",\n",
    "        \"INGLES\", \"H_AULA_PRES\", \"TAREFAS_ONLINE\", \"FALTAS\", \n",
    "    ],\n",
    "    'values': [\n",
    "        [\n",
    "            513949,\"Marli Quésia de Oliveira\",1,1,1,1,4.3,4.0,3.1,4.9,0,3,4,3,\n",
    "        ]\n",
    "    ]\n",
    "}\n",
    "\n",
    "print(\"\\n Payload de dados a ser classificada:\")\n",
    "print(json.dumps(scoring_payload, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = clientWML.deployments.score(\n",
    "    model_endpoint_url,\n",
    "    scoring_payload\n",
    ")\n",
    "\n",
    "print(\"\\n Resultados:\")\n",
    "print(json.dumps(result, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## Parabéns! \n",
    "\n",
    "Se tudo foi executado sem erros, você já tem um classificador baseado em machine learning encapsulado como uma API REST!\n",
    "\n",
    "Para testar a sua solução integrada com um assistente virtual e realizar a submissão, acesse a página:\n",
    "\n",
    "https://uninassau.maratona.dev\n",
    "\n",
    "Você irá precisar da endpoint url do seu modelo e das credenciais do WML :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
